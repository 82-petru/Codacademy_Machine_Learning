{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron\n",
    "Is an artificial neuron\n",
    "It has three main components : inputs, weights, output \n",
    "input coresponding to a feature \n",
    "Weight, input also have a weight which assign a certain amount of importance, input with bigger weight will have an higher influence on determing the output \n",
    "Output finally perceptronn use the input and weight to produce an aoutput "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 calculating the weighted_sum = Sum(xi*wn...xn*wn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 Constrain the weighted sum \n",
    "Imagine we have large range values(100 ...1000) and  the goal is to predict wether or not soemthing would occur, like so binary \n",
    "1 for Yes and 0 for No, activation function come in .These are special functions that transform the weighted sum into a desired and constrained output.\n",
    "activation functions are mathematical equation that determine neuron networks, is a non-linear function that decides if  the \n",
    "output from a neuron should be propagated forward or not, is like a treeshold which decide if the output is important\n",
    "y = ASum(xi*wi + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 Training error \n",
    "A quantity that mesasure \"how bad \" the perceptron is performing training error = actual label - predicted label \n",
    "Tweaking the weights until all possible labels are corectly predicted by the percepton\n",
    "while loops is to train perceptron until found a line to separate the positive and negative labels \n",
    "total_error to update the total error the percepton makes in each round \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4 Tweaking the weights \n",
    "Tweking the weights until all possible labels are cirectly predicted by the perceptron, this mean that multiple passes need to be made through training_set until percepetron algorithm comes to a halt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "class Perceptron:\n",
    "    def __init__(self, num_inputs = 3, weights = [1, 1, 1]):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.weights = weights \n",
    "    def weighted_sum(self, inputs):\n",
    "        weighted_sum = 0\n",
    "        for i in range(self.num_inputs):\n",
    "            weighted_sum += inputs[i] * self.weights[i]\n",
    "        return weighted_sum \n",
    "    def activation(self, weighted_sum):\n",
    "        if weighted_sum >= 0:\n",
    "            return 1\n",
    "        if weighted_sum <= 0:\n",
    "            return -1\n",
    "    def training(self, training_set):\n",
    "        foundLine = False\n",
    "        while not foundLine:\n",
    "            total_error = 0\n",
    "            for inputs in training_set:\n",
    "                prediction = self.activation(self.weighted_sum(inputs))\n",
    "                actual = training_set[inputs]\n",
    "                error = actual - prediction \n",
    "                total_error += abs(error)\n",
    "                for i in range(self.num_inputs):\n",
    "                    self.weights[i] += error * inputs[i]\n",
    "                    \n",
    "            slope = - self.weights[0] / self.weights[1]\n",
    "            intercept = -self.weights[2]/self.weights[1]\n",
    "            y1 = (slope * 0) + intercept \n",
    "            y2 = (slope * 50) + intercept\n",
    "            lines.append([[0, 50], [y1, y2]])\n",
    "            \n",
    "            if total_error == 0:\n",
    "                foundLine = True\n",
    "        return lines\n",
    "                \n",
    "small_training_set = {(0,3):1, (3,0):-1, (0,-3):-1, (-3,0):1}      \n",
    "cool_perceptron = Perceptron()\n",
    "#perceptron = cool_perceptron.weighted_sum([24, 55])\n",
    "#print(perceptron)\n",
    "#print(cool_perceptron.activation(perceptron))\n",
    "#print(cool_perceptron.training(small_training_set))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. when you should use perceptron?\n",
    "Use perceptron when the data are liniary separable.\n",
    "\n",
    "B. Parameters and inputs for perceptron?\n",
    "1. point coordonate vector (x1, y1, 1) we need one as constant term \n",
    "2. perceptron coeficients(weights) w = (wo, w1, w2), is a vector and tell us what the line looks like , number of weights shows us the number of dimension in our example we worked in tw dimension and we had 2 cofficients, the reason we have one more is because we need the constant term.\n",
    "3. learning rate \"nu\" we can think as this paramete as how fast percepton converges  to this line to separates the two classes the higher learning rate the faster make steps and smaller steps result in higher time to separate the two classes\n",
    "\n",
    "C. How we put this togeteher \n",
    "1. Well, we have two vector with same size, take the product of each item and sum it(wo*1 + x1*w1 + y1w2)\n",
    "2. take that quantity between vector x and vector w and if it is higher 0 assign to x and is is less assign to delta\n",
    "3. if you simplify it you'll get exactly the ecuation of a line in a plane y > -2x, so how percepton works take the w and transform it in a line \n",
    "4. Next step is to fit the line in order to separate the two classes from each other, how we do it?\n",
    "5. Update step requires to generate a new weight for each element in w matrix the new one will be called w' prime w' = wi + nu*d*xi d= {1 if should be in upper {-1 if should be in lower d refers to the type of class and are called  here point belongs to  upper or  lower group, with respect of this classification d receive assigment for 1 or -1  Example: w1 = w1 + 0.2 * (-1) * (1) = 0.2 \n",
    "6. After we do all replacments we repeat step 1 and step 2\n",
    "7. Replace values in step 5 and result would be y1 > -2/3*x1 + 2/9, means that slope has been changed from -2 to -2/3, in this case no repetion need more, all points are classified by the percepton line\n",
    "D. Extention of Percepton \n",
    "This case apply when one class of points are distributed in circle and second class souround the first group, like a donuts. For this case convert in  polar coordonates and then separate line... see in different topic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
